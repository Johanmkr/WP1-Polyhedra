\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{tishbyDeepLearningInformation2015a,shwartz-zivOpeningBlackBox2017}
\citation{geigerInformationPlaneAnalyses2022}
\citation{serraBoundingCountingLinear2018,haninComplexityLinearRegions2019}
\citation{haninDeepReLUNetworks2019}
\citation{liuReLUNeuralNetworks2023,sattelbergLocallyLinearAttributes2023,humayunSplineCamExactVisualization2024}
\bibdata{Polyhedral_Decomposition}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Preliminary example. Random layer, $\mathbb  {R}^2\rightarrow \mathbb  {R}^3$, divides its input space into 7 convex regions. The activation vector $q=[1,0,1]$ (indicating which neuron is active) corresponds to the red region. Each activation pattern corresponds to a convex region in input space, of which there can be at most $2^{H}$. Only a subset are feasible. For more complex layers and networks, the idea is that these regions can be used as ``natural bins'' when estimating information theoretic quantities.}}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:regions}{{1}{1}{Preliminary example. Random layer, $\mathbb {R}^2\rightarrow \mathbb {R}^3$, divides its input space into 7 convex regions. The activation vector $q=[1,0,1]$ (indicating which neuron is active) corresponds to the red region. Each activation pattern corresponds to a convex region in input space, of which there can be at most $2^{H}$. Only a subset are feasible. For more complex layers and networks, the idea is that these regions can be used as ``natural bins'' when estimating information theoretic quantities}{figure.caption.1}{}}
\newlabel{fig:regions@cref}{{[figure][1][]1}{[1][1][]1}}
\bibcite{geigerInformationPlaneAnalyses2022}{{1}{2022}{{Geiger}}{{}}}
\bibcite{haninComplexityLinearRegions2019}{{2}{2019{a}}{{Hanin \& Rolnick}}{{Hanin and Rolnick}}}
\bibcite{haninDeepReLUNetworks2019}{{3}{2019{b}}{{Hanin \& Rolnick}}{{Hanin and Rolnick}}}
\bibcite{humayunSplineCamExactVisualization2024}{{4}{2024}{{Humayun et~al.}}{{Humayun, Balestriero, Balakrishnan, and Baraniuk}}}
\bibcite{liuReLUNeuralNetworks2023}{{5}{2023}{{Liu et~al.}}{{Liu, Cole, Peterson, and Kirby}}}
\bibcite{sattelbergLocallyLinearAttributes2023}{{6}{2023}{{Sattelberg et~al.}}{{Sattelberg, Cavalieri, Kirby, Peterson, and Beveridge}}}
\bibcite{serraBoundingCountingLinear2018}{{7}{2018}{{Serra et~al.}}{{Serra, Tjandraatmadja, and Ramalingam}}}
\bibcite{shwartz-zivOpeningBlackBox2017}{{8}{2017}{{{Shwartz-Ziv} \& Tishby}}{{{Shwartz-Ziv} and Tishby}}}
\bibcite{tishbyDeepLearningInformation2015a}{{9}{2015}{{Tishby \& Zaslavsky}}{{Tishby and Zaslavsky}}}
\bibstyle{iclr2025_conference}
\gdef \@abspage@last{2}
